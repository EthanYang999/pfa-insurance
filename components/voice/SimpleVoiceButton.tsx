'use client';

import { useState, useRef, useCallback, useEffect, forwardRef, useImperativeHandle } from 'react';
import { Button } from '@/components/ui/button';
import { Mic, MicOff, Volume2, VolumeX } from 'lucide-react';
import { Badge } from '@/components/ui/badge';

import { createAudioManager, type AudioManager } from '@/lib/voice/audio-manager';
import { StreamingTTSProcessor } from '@/lib/voice/streaming-tts';
import type { VoiceStatus } from '@/types/voice';

interface SimpleVoiceButtonProps {
  onUserSpeech?: (transcript: string) => void;
  onStatusChange?: (status: VoiceStatus) => void;
  disabled?: boolean;
  className?: string;
}

export interface SimpleVoiceButtonRef {
  speakText: (text: string) => Promise<void>;
  processTextChunk: (chunk: string) => Promise<void>;
  finishStreaming: () => Promise<void>;
  resetStreaming: () => void;
  getStatus: () => VoiceStatus;
  isActive: () => boolean;
  startListening: () => void;
  stopListening: () => void;
}

const SimpleVoiceButton = forwardRef<SimpleVoiceButtonRef, SimpleVoiceButtonProps>(({
  onUserSpeech,
  onStatusChange,
  disabled = false,
  className = ''
}, ref) => {
  
  const [status, setStatus] = useState<VoiceStatus>('STOPPED');
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);

  const audioManagerRef = useRef<AudioManager | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const streamingTTSRef = useRef<StreamingTTSProcessor | null>(null);
  const isInitializedRef = useRef(false);

  // æ›´æ–°çŠ¶æ€
  const updateStatus = useCallback((newStatus: VoiceStatus) => {
    setStatus(newStatus);
    onStatusChange?.(newStatus);
  }, [onStatusChange]);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  const initializeSpeechRecognition = useCallback(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
      return false;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'zh-CN';
    recognition.interimResults = false;
    recognition.continuous = false;
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      console.log('è¯­éŸ³è¯†åˆ«å¯åŠ¨');
      setIsRecording(true);
      updateStatus('LISTENING');
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const transcript = event.results[0][0].transcript;
      const confidence = event.results[0][0].confidence;
      console.log(`è¯†åˆ«ç»“æœ: "${transcript}" (ç½®ä¿¡åº¦: ${(confidence * 100).toFixed(1)}%)`);
      
      setIsRecording(false);
      updateStatus('THINKING');
      onUserSpeech?.(transcript);
    };

    recognition.onerror = (event: any) => {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
      setIsRecording(false);
      if (status !== 'STOPPED') {
        updateStatus('IDLE');
      }
    };

    recognition.onend = () => {
      console.log('è¯­éŸ³è¯†åˆ«ç»“æŸ');
      setIsRecording(false);
      if (status === 'LISTENING') {
        updateStatus('IDLE');
      }
    };

    recognitionRef.current = recognition;
    return true;
  }, [onUserSpeech, status, updateStatus]);

  // åˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
  const initializeAudioManager = useCallback(() => {
    if (audioManagerRef.current) return;

    const audioManager = createAudioManager({
      onPlay: () => {
        console.log('å¼€å§‹æ’­æ”¾éŸ³é¢‘');
        setIsPlaying(true);
        updateStatus('SPEAKING');
      },
      
      onStateChange: (state) => {
        setIsPlaying(state.isPlaying);
        if (!state.isPlaying && state.queueLength === 0 && status === 'SPEAKING') {
          updateStatus('IDLE');
        }
      },
      
      onError: (error) => {
        console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', error);
      }
    });

    audioManagerRef.current = audioManager;
    
    // åˆå§‹åŒ–æµå¼TTSå¤„ç†å™¨
    streamingTTSRef.current = new StreamingTTSProcessor(audioManager);
    
    console.log('éŸ³é¢‘ç®¡ç†å™¨å’Œæµå¼TTSå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ');
  }, [status, updateStatus]);

  // åˆå§‹åŒ–ç®¡ç†å™¨
  const initializeManagers = useCallback(async () => {
    if (isInitializedRef.current) return true;

    try {
      // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
      if (!initializeSpeechRecognition()) {
        console.error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
        return false;
      }

      // åˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
      initializeAudioManager();
      
      isInitializedRef.current = true;
      console.log('è¯­éŸ³ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ');
      return true;

    } catch (error: any) {
      console.error('åˆå§‹åŒ–è¯­éŸ³ç»„ä»¶å¤±è´¥:', error);
      return false;
    }
  }, [initializeSpeechRecognition, initializeAudioManager]);

  // å¼€å§‹è†å¬
  const startListening = useCallback(async () => {
    const initialized = await initializeManagers();
    if (!initialized) return;

    if (isRecording) {
      console.log('å·²åœ¨å½•éŸ³ä¸­');
      return;
    }

    // å¦‚æœæ­£åœ¨æ’­æ”¾ï¼Œå…ˆåœæ­¢
    if (isPlaying && audioManagerRef.current) {
      audioManagerRef.current.interrupt();
      setIsPlaying(false);
    }

    try {
      if (recognitionRef.current) {
        recognitionRef.current.start();
      }
    } catch (error: any) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
    }
  }, [initializeManagers, isRecording, isPlaying]);

  // åœæ­¢è†å¬
  const stopListening = useCallback(() => {
    if (recognitionRef.current && isRecording) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.warn('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      }
    }
    
    if (audioManagerRef.current) {
      audioManagerRef.current.stop();
    }

    setIsRecording(false);
    setIsPlaying(false);
    updateStatus('STOPPED');
    console.log('è¯­éŸ³åŠŸèƒ½å·²åœæ­¢');
  }, [isRecording, updateStatus]);

  // å¼€å§‹è¯­éŸ³äº¤äº’
  const startVoice = useCallback(async () => {
    const initialized = await initializeManagers();
    if (!initialized) return;
    
    updateStatus('IDLE');
    console.log('è¯­éŸ³äº¤äº’å·²å¯åŠ¨');
  }, [initializeManagers, updateStatus]);

  // åœæ­¢è¯­éŸ³äº¤äº’
  const stopVoice = useCallback(() => {
    stopListening();
  }, [stopListening]);

  // åˆ‡æ¢è¯­éŸ³çŠ¶æ€
  const toggleVoice = useCallback(async () => {
    if (disabled) return;
    
    if (status === 'STOPPED') {
      await startVoice();
    } else {
      stopVoice();
    }
  }, [disabled, status, startVoice, stopVoice]);

  // å¤„ç†AIå“åº”çš„TTSï¼ˆå®Œæ•´æ–‡æœ¬ï¼‰
  const speakText = useCallback(async (text: string) => {
    if (!text.trim()) return;
    
    // å¦‚æœéœ€è¦ï¼Œå…ˆåˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
    if (!audioManagerRef.current) {
      await initializeManagers();
    }
    
    if (!audioManagerRef.current) {
      console.error('éŸ³é¢‘ç®¡ç†å™¨æœªåˆå§‹åŒ–');
      return;
    }
    
    console.log('æ·»åŠ å®Œæ•´æ–‡æœ¬åˆ°è¯­éŸ³é˜Ÿåˆ—:', text.substring(0, 50) + '...');
    updateStatus('SPEAKING');
    await audioManagerRef.current.addToQueue(text);
  }, [updateStatus, initializeManagers]);

  // æµå¼å¤„ç†æ–‡æœ¬å—
  const processTextChunk = useCallback(async (chunk: string) => {
    if (!chunk?.trim()) return;
    
    // ğŸ”’ ä¸¥æ ¼æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
    if (!isInitializedRef.current) {
      const initialized = await initializeManagers();
      if (!initialized) {
        console.error('ç»„ä»¶åˆå§‹åŒ–å¤±è´¥');
        return;
      }
    }
    
    if (!streamingTTSRef.current) {
      console.error('æµå¼TTSå¤„ç†å™¨æœªåˆå§‹åŒ–');
      return;
    }
    
    // å¦‚æœè¿˜æœªå¼€å§‹æ’­æ”¾ï¼Œè®¾ç½®çŠ¶æ€ä¸ºSPEAKING
    if (status !== 'SPEAKING') {
      updateStatus('SPEAKING');
    }
    
    console.log('æµå¼å¤„ç†æ–‡æœ¬å—:', chunk.substring(0, 30) + '...');
    await streamingTTSRef.current.processTextChunk(chunk);
  }, [initializeManagers, status, updateStatus]);

  // å®Œæˆæµå¼å¤„ç†
  const finishStreaming = useCallback(async () => {
    if (!streamingTTSRef.current) return;
    
    console.log('å®Œæˆæµå¼TTSå¤„ç†');
    await streamingTTSRef.current.processRemainingText();
  }, []);

  // é‡ç½®æµå¼å¤„ç†
  const resetStreaming = useCallback(() => {
    if (streamingTTSRef.current) {
      console.log('é‡ç½®æµå¼TTSå¤„ç†å™¨');
      streamingTTSRef.current.reset();
    }
  }, []);

  // æš´éœ²ç»™çˆ¶ç»„ä»¶çš„æ–¹æ³•
  useImperativeHandle(ref, () => ({
    speakText,
    processTextChunk,
    finishStreaming,
    resetStreaming,
    getStatus: () => status,
    isActive: () => status !== 'STOPPED',
    startListening,
    stopListening
  }), [speakText, processTextChunk, finishStreaming, resetStreaming, status, startListening, stopListening]);

  // æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      audioManagerRef.current?.destroy();
      
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (error) {
          console.warn('æ¸…ç†è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
        }
      }
    };
  }, []);

  // è·å–æŒ‰é’®å›¾æ ‡å’Œæ ·å¼
  const getButtonConfig = () => {
    if (isRecording) {
      return {
        icon: <MicOff className="w-4 h-4 text-red-500" />,
        variant: 'destructive' as const,
        text: 'å½•éŸ³ä¸­',
        onClick: stopListening
      };
    }
    
    if (isPlaying) {
      return {
        icon: <Volume2 className="w-4 h-4 text-blue-500" />,
        variant: 'default' as const,
        text: 'æ’­æ”¾ä¸­',
        onClick: () => audioManagerRef.current?.interrupt()
      };
    }
    
    if (status === 'STOPPED') {
      return {
        icon: <Mic className="w-4 h-4" />,
        variant: 'outline' as const,
        text: 'å¯åŠ¨è¯­éŸ³',
        onClick: toggleVoice
      };
    }
    
    return {
      icon: <Mic className="w-4 h-4 text-green-500" />,
      variant: 'default' as const,
      text: 'å¼€å§‹è¯´è¯',
      onClick: startListening
    };
  };

  const buttonConfig = getButtonConfig();

  return (
    <div className={`flex items-center gap-2 ${className}`}>
      <Button
        onClick={buttonConfig.onClick}
        disabled={disabled}
        variant={buttonConfig.variant}
        size="sm"
        className="relative"
        title={buttonConfig.text}
      >
        {buttonConfig.icon}
        {(isRecording || isPlaying) && (
          <div className="absolute -top-1 -right-1 w-2 h-2 bg-red-500 rounded-full animate-pulse" />
        )}
      </Button>
      
      {status !== 'STOPPED' && (
        <Badge 
          variant="secondary" 
          className="text-xs"
        >
          {isRecording ? 'å½•éŸ³ä¸­' : 
           isPlaying ? 'æ’­æ”¾ä¸­' : 
           status === 'THINKING' ? 'å¤„ç†ä¸­' : 
           status === 'SPEAKING' ? 'å›ç­”ä¸­' : 'å¾…æœº'}
        </Badge>
      )}
    </div>
  );
});

SimpleVoiceButton.displayName = 'SimpleVoiceButton';

export default SimpleVoiceButton;
export type { SimpleVoiceButtonRef };